{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "BfGNIbu09MVT",
    "outputId": "51a40e41-cb6b-4b58-f9a0-16e05b8e9f03"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "gsBDTv_g-IIh",
    "outputId": "9091e3c1-bbc6-40f9-e4bc-fc96affa2bb9"
   },
   "outputs": [],
   "source": [
    "# !pip install -q keras\n",
    "# !pip install -q pandas\n",
    "# !pip install -q numpy\n",
    "# !pip install -q tensorflow\n",
    "# !pip install -U -q PyDrive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9t_JNmdIXw-5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir(\"drive/My Drive/colab_datas/teknofest/keras-retinanet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K5VuyBJu96st",
    "outputId": "4487a844-5fb2-4a6e-d1a0-434b451173eb"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NOqVkc7393iB",
    "outputId": "96a12e39-8bd5-441c-9f63-a41c69562619"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sX6FNadHqvYh"
   },
   "source": [
    "## Video Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0N4xtyVajHIi"
   },
   "outputs": [],
   "source": [
    "input_video=\"drone_1\"\n",
    "\n",
    "vidcap = cv2.VideoCapture('drone_night_footage/{}.mp4'.format(input_video))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "frames=[]\n",
    "while success:\n",
    "    frames.append(image)     # save frame as JPEG file      \n",
    "    success,image = vidcap.read()\n",
    "    # print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98Aqrv8njLyf"
   },
   "outputs": [],
   "source": [
    "frames=glob.glob(\"photos/test_images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "zPZHomHnjYrU",
    "outputId": "90552738-61c3-4c7d-a1e0-a18a6df3f300",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_to_names = {0: 'yaya', 1: 'arac'}\n",
    "!python keras_retinanet/bin/convert_model.py ./snapshots_woconfig_waug/resnet50_csv_11.h5 ./snapshots/infer_model.h5\n",
    "model = models.load_model(\"./snapshots/infer_model.h5\", backbone_name='resnet50')\n",
    "resnet50_images=[]\n",
    "for image in tqdm(frames):# load image\n",
    "    sha=image.shape\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image,max_side=3000)\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    boxes /= scale\n",
    "\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < 0.5:\n",
    "            break\n",
    "        color = label_color(label)\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "        \n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "    resnet50_images.append(draw)\n",
    "# os.mkdir(\"snapshots_resnet50_csv_01\")\n",
    "# for i in range(len(resnet50_images)):\n",
    "#     image_=cv2.cvtColor(resnet50_images[i],cv2.COLOR_BGR2RGB)\n",
    "#     cv2.imwrite(\"snapshots_resnet50_csv_01/{}.jpg\".format(i),image_)\n",
    "#     # plt.figure(figsize=(20, 20))\n",
    "#     # plt.axis('off')\n",
    "#     # plt.imshow(image)\n",
    "#     # plt.show()\n",
    "#     # plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gxYbL53TkFjz",
    "outputId": "b6d62a94-b38f-42ee-c3f7-e6edb7be127a"
   },
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "height, width, layers = resnet50_images[0].shape\n",
    "\n",
    "out = cv2.VideoWriter(\"drone_night_footage/{}_pred_lastest_waug.avi\".format(input_video),cv2.VideoWriter_fourcc(*\"MJPG\"), 60, (width,height))\n",
    "for i in tqdm(range(len(resnet50_images))):\n",
    "    out.write(resnet50_images[i])\n",
    "    # cv2.imwrite(\"drone_night_footage/\"+str(i)+\".jpg\",resnet50_images[i])\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AUgaZWym3CR"
   },
   "outputs": [],
   "source": [
    "# [os.remove(i) for i in glob.glob(\"drone_night_footage/*.jpg\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJA4ZJUbqyQA"
   },
   "source": [
    "## Modellerin birleşmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B52-0MCYygSr"
   },
   "outputs": [],
   "source": [
    "paths=glob.glob(\"photos/test_images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znNz1xF5xjK0"
   },
   "outputs": [],
   "source": [
    "# 4 farklı modelin karsılastırılması \n",
    "\n",
    "model_paths=[\"./snapshots/son_50.h5\",\"./snapshots/resnet101_csv_06.h5\",\"./snapshots_woconfig/resnet50_csv_14.h5\",\"./snapshots_woconfig_waug/resnet50_csv_11.h5\"]\n",
    "labels_to_names = {0: 'yaya', 1: 'arac'}\n",
    "pred_dict={}\n",
    "for model_path in model_paths:\n",
    "    !python keras_retinanet/bin/convert_model.py $model_path ./snapshots/infer_model.h5\n",
    "    if \"resnet101\" in model_path:\n",
    "        model = models.load_model(\"./snapshots/infer_model.h5\", backbone_name='resnet101')\n",
    "    else:\n",
    "        model = models.load_model(\"./snapshots/infer_model.h5\", backbone_name='resnet50')\n",
    "    pred_dict[model_path]=[]\n",
    "    print(model_path)\n",
    "    for path in tqdm(paths):\n",
    "        image=read_image_bgr(path)\n",
    "        sha=image.shape\n",
    "        # draw = image.copy()\n",
    "        # draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "        image = preprocess_image(image)\n",
    "        image, scale = resize_image(image,max_side=3000)\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "        boxes /= scale\n",
    "        bbs=[]\n",
    "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            # color = label_color(label)\n",
    "            b = box.astype(int)\n",
    "            bbs.append([path,b[0],b[1],b[2],b[3],labels_to_names[label], score])\n",
    "            # draw_box(draw, b, color=color)\n",
    "            # caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "            # draw_caption(draw, b, caption)\n",
    "        # font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # cv2.putText(draw,model_path.split(\"/\")[-1].split(\".\")[0],(10,500), font, 4,(255,255,255),2,cv2.LINE_AA)\n",
    "        pred_dict[model_path].append(bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kho-0neTntEk",
    "outputId": "5d5e7cf9-ff29-48c9-ac35-ff7e3b4bd212"
   },
   "outputs": [],
   "source": [
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvfVMyPZue1w"
   },
   "outputs": [],
   "source": [
    "# pred_dict[\"./snapshots/son_50.h5\"]=[i for i in pred_dict[\"./snapshots/son_50.h5\"]  if not len(i)==0]\n",
    "# pred_dict[\"./snapshots/resnet101_csv_06.h5\"]=[i for i in pred_dict[\"./snapshots/resnet101_csv_06.h5\"]  if not len(i)==0]\n",
    "# pred_dict[\"./snapshots_woconfig_waug/resnet50_csv_11.h5\"]=[i for i in pred_dict[\"./snapshots_woconfig_waug/resnet50_csv_11.h5\"]  if not len(i)==0]\n",
    "# pred_dict[\"./snapshots_woconfig/resnet50_csv_14.h5\"]=[i for i in pred_dict[\"./snapshots_woconfig/resnet50_csv_14.h5\"]  if not len(i)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95g1rn-_vOMa"
   },
   "outputs": [],
   "source": [
    "df=[]\n",
    "for key in pred_dict.keys():\n",
    "  for frame in pred_dict[key]:\n",
    "    for pred in frame[:-1]:\n",
    "      pred.append(key)\n",
    "      df.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ic3Eiu1n8I2"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2psWnaSwb3T"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"pred_model_comparison.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "hoGs-c120eon",
    "outputId": "33ef9899-b8d5-418f-cb2f-132d4efa0841"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "iNs5KEjq2eTz",
    "outputId": "d637397e-56c5-4a81-d759-c08a08da7dbe"
   },
   "outputs": [],
   "source": [
    "df[7].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBWwsa7t3cof"
   },
   "outputs": [],
   "source": [
    "labels_to_names_rev={'yaya':0,  'arac':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_rIgHK0k_wu"
   },
   "outputs": [],
   "source": [
    "frame_paths=pd.DataFrame(df[0].value_counts().index)\n",
    "frame_paths[1]=frame_paths[0].apply(lambda x:x.split(\"/\")[-1].split(\".\")[0]).astype(int)\n",
    "frame_paths=frame_paths.sort_values(by=[1])\n",
    "frame_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwbn9jUUyDp2"
   },
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "# height, width, layers = image.shape\n",
    "\n",
    "out = cv2.VideoWriter(\"project_11.avi\",cv2.VideoWriter_fourcc(*\"DIVX\"), 7.5, (1920,1080))\n",
    "\n",
    "for frame in tqdm(frame_paths[0].values):\n",
    "    image=cv2.imread(frame)\n",
    "    images_dict={}\n",
    "    models=df[7].value_counts().index\n",
    "    for model_path in models:\n",
    "        image_1=image.copy()\n",
    "        unq_df=df.loc[(df[7]==model_path)&(df[0]==frame)]\n",
    "        for bb in unq_df.values:\n",
    "            color = label_color(labels_to_names_rev[bb[5]])\n",
    "            draw_box(image_1, bb[1:5], color=color)\n",
    "            caption = \"{} {:.3f}\".format(bb[5], bb[6])\n",
    "            draw_caption(image_1, bb[1:5], caption)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(image_1,model_path.split(\"/\")[-1].split(\".\")[0],(10,500), font, 4,(255,255,255),2,cv2.LINE_AA)\n",
    "        images_dict[model_path]=image_1.copy()\n",
    "    image_1=np.concatenate((images_dict[\"./snapshots/son_50.h5\"],images_dict[\"./snapshots_woconfig_waug/resnet50_csv_11.h5\"]),axis=0)\n",
    "    image_2=np.concatenate((images_dict[\"./snapshots_woconfig/resnet50_csv_14.h5\"],images_dict[\"./snapshots/resnet101_csv_06.h5\"]),axis=0)\n",
    "    image_1=np.concatenate((image_1,image_2),axis=1)\n",
    "    image_1=cv2.resize(image_1,(1920,1080))\n",
    "    out.write(image_1)\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sG79ErBAHM3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKBmDwU5je8M"
   },
   "source": [
    "## Video cıkar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOQB8zK3kZWT"
   },
   "outputs": [],
   "source": [
    "paths=glob.glob(\"photos/test_images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[i.replace(\"\\\\\",\"/\") for i in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds=pd.read_csv(\"resnet50_preds_scaled.csv\")\n",
    "model_preds[\"path\"]=model_preds[\"path\"].apply(lambda x: x.replace(\"\\\\\",\"/\"))\n",
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "VvudI1M5jhgF",
    "outputId": "0461e228-a49e-477b-89ee-ae5fef9c35b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1886/1886 [01:14<00:00, 25.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from os.path import isfile, join\n",
    "# height, width, layers = image.shape\n",
    "out = cv2.VideoWriter(\"project_1222.avi\",cv2.VideoWriter_fourcc(*\"DIVX\"), 7.5, (960,540))\n",
    "\n",
    "for frame in tqdm(paths):\n",
    "    image=cv2.imread(frame)\n",
    "    images_dict={}\n",
    "    image_1=image.copy()\n",
    "    image_1=cv2.cvtColor(image_1,cv2.COLOR_BGR2RGB)\n",
    "    unq_df=model_preds[model_preds[\"path\"]==frame]\n",
    "    for bb in unq_df.values:\n",
    "        color = label_color(labels_to_names_rev[bb[5]])\n",
    "        draw_box(image_1, bb[1:5], color=color)\n",
    "        caption = \"{} {:.3f}\".format(bb[5], bb[6])\n",
    "        draw_caption(image_1, bb[1:5], caption)\n",
    "    image_1=cv2.resize(image_1,(960,540))\n",
    "    out.write(image_1)\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IPJVrDRHNYS"
   },
   "source": [
    "## Blended predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "id": "7nC5sMdi4HCq",
    "outputId": "7a09d785-299a-466b-a4cb-b801b7957a8f"
   },
   "outputs": [],
   "source": [
    "preds=pd.read_csv(\"./pred_model_comparison.csv\")\n",
    "preds.columns=[\"path\",\"x1\",\"y1\",\"x2\",\"y2\",\"label\",\"confidence\",\"model\"]\n",
    "preds[\"area\"]=(preds[\"x2\"]-preds[\"x1\"])*(preds[\"y2\"]-preds[\"y1\"])\n",
    "preds[\"center_x\"]=((preds[\"x2\"].astype(int)+preds[\"x1\"].astype(int))/2).astype(int)\n",
    "preds[\"center_y\"]=((preds[\"y2\"].astype(int)+preds[\"y1\"].astype(int))/2).astype(int)\n",
    "preds=preds.sort_values(by=[\"path\",\"center_x\",\"center_y\"])\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VSWW7WyfIBhB",
    "outputId": "e855776b-6c25-4d72-f80e-8db59f3b7654"
   },
   "outputs": [],
   "source": [
    "preds=preds.drop(preds.loc[preds[\"model\"]==\"./snapshots/resnet101_csv_06.h5\"].index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "id": "JkwP-B42JTlS",
    "outputId": "e23f45d0-e21c-4bfb-b0e3-c78d80608a7b"
   },
   "outputs": [],
   "source": [
    "frame_paths=pd.DataFrame(preds[\"path\"].value_counts().index)\n",
    "frame_paths[1]=frame_paths[0].apply(lambda x:x.split(\"/\")[-1].split(\".\")[0]).astype(int)\n",
    "frame_paths=frame_paths.sort_values(by=[1])\n",
    "frame_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "wYH8FRfBAjCY",
    "outputId": "3fe61f25-566e-4c7b-84cb-7ddbcd2a81d5"
   },
   "outputs": [],
   "source": [
    "for i, row in preds.iterrows():\n",
    "    break\n",
    "i,row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AG6B91GI-ygt"
   },
   "outputs": [],
   "source": [
    "# buraya iki data data frame i alarak ensemble i koy\n",
    "\n",
    "def find_intersection(df1,df2):\n",
    "    new_preds=[]\n",
    "    idx_tbd_1=[]\n",
    "    idx_tbd_2=[]\n",
    "    for idx_df1,bb_df1 in df1.iterrows():\n",
    "        for idx_df2,bb_df2 in df2.iterrows():\n",
    "            if abs(bb_df1[\"center_x\"]-bb_df2[\"center_x\"])<=20 and abs(bb_df1[\"center_y\"]-bb_df2[\"center_y\"])<=20:\n",
    "                frame=bb_df1[\"path\"]\n",
    "                x1=min(bb_df1[\"x1\"],bb_df2[\"x1\"])\n",
    "                y1=min(bb_df1[\"y1\"],bb_df2[\"y1\"])\n",
    "                x2=min(bb_df1[\"x2\"],bb_df2[\"x2\"])\n",
    "                y2=min(bb_df1[\"y2\"],bb_df2[\"y2\"])\n",
    "                label_=bb_df1[\"label\"]\n",
    "                conf=bb_df1[\"confidence\"]\n",
    "                idx_tbd_1.append(idx_df1)\n",
    "                idx_tbd_2.append(idx_df2)\n",
    "                new_preds.append([frame,x1,y1,x2,y2,label_,conf,\"ens\",(x2-x1)*(y2-y1),bb_df1[\"center_x\"],bb_df1[\"center_y\"]])\n",
    "    df1=df1.drop(idx_tbd_1)\n",
    "    df2=df2.drop(idx_tbd_2)\n",
    "    new_preds=pd.DataFrame(new_preds)\n",
    "    try:\n",
    "        new_preds.columns=df1.columns\n",
    "    except:\n",
    "        pass\n",
    "    return df1,df2,new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wR-UYE-EOQKQ",
    "outputId": "01769f9e-a657-4d60-e726-37a6305dace4"
   },
   "outputs": [],
   "source": [
    "indexes_tbd=[]\n",
    "model_preds=[]\n",
    "for frame in tqdm(frame_paths[0].values):\n",
    "    unq_df=preds.loc[preds[\"path\"]==frame]\n",
    "    son_50_model=unq_df.loc[unq_df[\"model\"]==\"./snapshots/son_50.h5\"]\n",
    "    confident_model=unq_df.loc[unq_df[\"model\"]==\"./snapshots_woconfig/resnet50_csv_14.h5\"]\n",
    "    augmented_model=unq_df.loc[unq_df[\"model\"]==\"./snapshots_woconfig_waug/resnet50_csv_11.h5\"]\n",
    "    son_1,conf_1,ens_1=find_intersection(son_50_model,confident_model)\n",
    "    ens_2,aug_1,ens_3=find_intersection(ens_1,augmented_model)\n",
    "    for i in son_1.values:\n",
    "        if not len(i)==0:\n",
    "            model_preds.append(i)\n",
    "    for i in conf_1.values:\n",
    "        if not len(i)==0:\n",
    "            model_preds.append(i)\n",
    "    for i in ens_2.values:\n",
    "        if not len(i)==0:\n",
    "            model_preds.append(i)\n",
    "    for i in aug_1.values:\n",
    "        if not len(i)==0:\n",
    "            model_preds.append(i)\n",
    "    for i in ens_3.values:\n",
    "        if not len(i)==0:\n",
    "            model_preds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vmw1CcCDvGHe",
    "outputId": "355d7cbd-6444-40ed-df10-0b9960d67864"
   },
   "outputs": [],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGmOn9gIcXsd"
   },
   "outputs": [],
   "source": [
    "model_preds=pd.DataFrame(model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbThu7HXcawV"
   },
   "outputs": [],
   "source": [
    "model_preds.to_csv(\"preds_tuned.csv\",index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBbMwva9aRyK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sX6FNadHqvYh",
    "AJA4ZJUbqyQA"
   ],
   "machine_shape": "hm",
   "name": "pred_to_video_or_vice_versa.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
